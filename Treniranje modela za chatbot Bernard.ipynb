{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2cebfc",
   "metadata": {},
   "source": [
    "# Treniranje modela za chatbot Bernard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de5ff9",
   "metadata": {},
   "source": [
    "Ovaj Jupyter notebook predstavlja proces treniranja modela baziranog na transformer tehnologiji.\n",
    "\n",
    "Rezultat nakon treniranja je model koji generira odgovor na na proizvoljan unos korisnika.\n",
    "\n",
    "Sama arhitektura modela je velikim dijelom bazirana na [Transformer modelu za razumijevanje jezika](https://www.tensorflow.org/text/tutorials/transformer), te je također velikim dijelom inspirirana sa [Chatbot programom](https://github.com/bryanlimy/tf2-transformer-chatbot) autora Bryan M. Li, doktoranda na sveučilištu u Edinbourghu. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161a2da",
   "metadata": {},
   "source": [
    "## O modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c0b8c",
   "metadata": {},
   "source": [
    "Kako b postigli razumijevanje ovakvog modela koji koristi transformer, potrebno je prethodno na teoretskoj razini proučiti tematike [generiranja teksta](https://www.tensorflow.org/text/tutorials/text_generation), [mehanizma pažnje](https://www.tensorflow.org/text/tutorials/nmt_with_attention) i [transformera](https://www.tensorflow.org/text/tutorials/transformer).\n",
    "\n",
    "Transformer model ovdje koristi mehanizam samopažnje - to jest sposobnost da se različite pozicije znakova u nizu koji čini unos obrade tako da se dobije odgovarajući reprezentant tog niza. \n",
    "Transformer tako stvara mnogobrojne slojeve koji koriste mehanizam samopažnje potrebne za postizanje odgovarajućeg rezultata. \n",
    "\n",
    "Za daljnje modifikacije ovog modela transformera i modifikaciju hiperparametara, preporučam referirati se na poznati članak pod naslovom [Attention is all you need](https://arxiv.org/abs/1706.03762)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2d052",
   "metadata": {},
   "source": [
    "Kako bi u opširnije opisali model i proveli treniranje, potrebno je učitati potrebne biblioteke.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf56fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow==2.9.1 in ./.local/lib/python3.9/site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow_datasets==4.6.0 in ./.local/lib/python3.9/site-packages (4.6.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in ./.local/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.local/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.9/site-packages (from tensorflow==2.9.1) (14.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (4.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in ./.local/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (61.2.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (21.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in ./.local/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.12)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.42.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.21.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.local/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.27.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in ./.local/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.16.0)\n",
      "Requirement already satisfied: dill in ./.local/lib/python3.9/site-packages (from tensorflow_datasets==4.6.0) (0.3.5.1)\n",
      "Requirement already satisfied: tensorflow-metadata in ./.local/lib/python3.9/site-packages (from tensorflow_datasets==4.6.0) (1.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow_datasets==4.6.0) (2.27.1)\n",
      "Requirement already satisfied: etils[epath] in ./.local/lib/python3.9/site-packages (from tensorflow_datasets==4.6.0) (0.8.0)\n",
      "Requirement already satisfied: promise in ./.local/lib/python3.9/site-packages (from tensorflow_datasets==4.6.0) (2.3)\n",
      "Requirement already satisfied: toml in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow_datasets==4.6.0) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow_datasets==4.6.0) (4.64.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.37.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0) (2.0.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.33.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.0)\n",
      "Requirement already satisfied: importlib_resources in ./.local/lib/python3.9/site-packages (from etils[epath]->tensorflow_datasets==4.6.0) (5.9.0)\n",
      "Requirement already satisfied: zipp in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from etils[epath]->tensorflow_datasets==4.6.0) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from packaging->tensorflow==2.9.1) (3.0.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/anaconda3-2022.05/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow_datasets==4.6.0) (1.53.0)\n",
      "Tensorflow version 2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.9.1 tensorflow_datasets==4.6.0\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "#za widgete\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "tf.keras.utils.set_random_seed(1234)\n",
    "\n",
    "print(f\"Tensorflow version {tf.__version__}\")\n",
    "\n",
    "#supress tensorflow complaining about everything he sees\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6147e0",
   "metadata": {},
   "source": [
    "## Korištenje GPU jedinica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d205863",
   "metadata": {},
   "source": [
    "Kako bi iskoristili brže mogućnosti računanja koje nam pruža GPU (eng. graphic processing unit, hrv. grafička procesna jedinica), možemo iskoristiti iduće ćelije. \n",
    "\n",
    "Ukoliko Vaš hardver omogućava korištenje GPU jedinica, preporučeno je se osloniti na njih umjesto na CPU (eng. central processing unit, hrv. centralna procesna jedinica). Postoji više načina [postavljanja GPU-a za uporabu](https://www.tensorflow.org/guide/gpu) i [strategijama za računanje na GPU jedinicama u slučajevima gdje ih ima više](https://www.tensorflow.org/guide/distributed_training)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e47a7",
   "metadata": {},
   "source": [
    "Provjerimo koliko grafičkih procesnih jedinica nam je dostupno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556d10af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9c55d",
   "metadata": {},
   "source": [
    "Mguće je prilagoditi program tako da se optimalno distribuirano izvršava na svim dostupnim grafičkim procesnim jedinicama, bez ručne provjere broja dostupnih jedinica. Distribuirano treniranje sa više grafičkih procesnih jedinica moguće je implementirati koristeći jednu od strategija za distribuirano treniranje koje koristi biblioteka Tensorflow.\n",
    "\n",
    "Za treniranje transformer modela programa Bernard je tako korištena strategija zrcaljenja (eng. mirrored strategy), koja je dovoljno dobra za naše potrebe. Kako bi Tensorflow konstruirao strategiju zrcaljenja, dovoljno je napraviti sljedeći korak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbe8975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e476dd3",
   "metadata": {},
   "source": [
    "Kako nijedan uređaj nije naveden u argumentu konstruktora strategije, koriste se svi dostupni GPU-ovi. Ako se ne pronađe nijedan GPU, koristit će se dostupan CPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71297dbb",
   "metadata": {},
   "source": [
    "## Hiperparametri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a6ece",
   "metadata": {},
   "source": [
    "Kako bi treniranje učinili bržim, parametri vezani uz transformer _num_layers_, _d_model_, i _units_ su smanjeni. \n",
    "Kako bi ovaj primjer bio jednostavan i brz, ograničavamo maksimalnu duljinu rečenice na MAX_LENGTH=40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b592e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maksimalna duljina rečenice\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# Maksimalni broj sample-ova za preprocesirati\n",
    "MAX_SAMPLES = 250000\n",
    "\n",
    "# Za dataset\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# Parametri za transformer\n",
    "NUM_LAYERS = 4\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Broj epoha\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c14ef",
   "metadata": {},
   "source": [
    "# Podaci za treniranje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2fccf",
   "metadata": {},
   "source": [
    "Set podataka koji ćemo koristiti je [Cornell Movie-Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html), koji sadrži više od 220,000 filmskih dijaloga.\n",
    "\n",
    "Sam dataset se sastoji od datoteka\n",
    "1. movie_conversations.txt - datoteka koja sadrži listu identifikacijskih ključeva (ID) razgovora\n",
    "2. movie_lines.txt - datoteka koja sadrži sam tekst razgovora asociranog sa nekim identifikacijskim ključem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8329f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    \"cornell_movie_dialogs.zip\",\n",
    "    origin=\"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\"\n",
    ")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, \"movie_lines.txt\")\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset, \"movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866344d",
   "metadata": {},
   "source": [
    "Promotrimo sadržaje datoteka. U tu svrhu, prvo definirajmo funkciju koja čita prvih par redaka datoteka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95c01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_lines(filename, limit):\n",
    "  result = []\n",
    "  with open(filename, 'r') as input_file:\n",
    "    # datoteke su iterabilne\n",
    "    for line_number, line in enumerate(input_file):\n",
    "      if line_number > limit:  # line_number počinje u 0\n",
    "        break\n",
    "      result.append(line)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372174e2",
   "metadata": {},
   "source": [
    "Tako je sadržaj datoteke __movie_lines.txt__ oblika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b3f9f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(*read_first_lines(path_to_movie_lines,5), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96feb34",
   "metadata": {},
   "source": [
    "A sadržaj datoteke __movie_conversations.txt__ je oblika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67eceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(*read_first_lines(path_to_movie_conversations,5), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df543cab",
   "metadata": {},
   "source": [
    "## Učitavanje i preprocesiranje podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c63326",
   "metadata": {},
   "source": [
    "Prvo ćemo definitrati funkciju za preprocesiranje podataka __preprocess_sentence__ . \n",
    "Ona preprocesira svaku rečenicu uklanjanjem posebnih znakova u njoj.\n",
    "Taj proces ima više koraka: \n",
    "1. stvara razmak između riječi i interpunkcije iza nje, npr. \"he is smart.\" => \"he is smart .\"\n",
    "    \n",
    "2. produljenje skraćenica (kontrakcija) iz engleskog jezika, npr. \"i'm\" => \"i am\"\n",
    "\n",
    "3. mijenjanje svih znakova koji nisu u skupu (a-z, A-Z, \".\", \"?\", \"!\", \",\") sa znakom razmaka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9898360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    # korak 1\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # korak 2\n",
    "    sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
    "    sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
    "    sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
    "    sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
    "    sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
    "    sentence = re.sub(r\"what's\", \"that is\", sentence)\n",
    "    sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
    "    sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "    sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
    "    sentence = re.sub(r\"n't\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
    "    sentence = re.sub(r\"'bout\", \"about\", sentence)\n",
    "    # korak 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1c71a",
   "metadata": {},
   "source": [
    "Pri treniranju na podacima je potrebno izvesti i dodatno pretprocesiranje podataka: u dokumentima skupa podataka je, uz linijski prikaz podatka, znak \"++\\$++\" korišten kao separator podataka u linijama dokumenta.\n",
    "\n",
    "Kako bi pravilno učitali podatke za treniranje kao parove filmskih replika, svaki par filmskih replika gdje jedna odgovara na drugu u razgovoru dijelimo na upit (eng. question) i odgovor (eng. answer).\n",
    "\n",
    "Kako bi dodatno pretprocesirali skup podataka, definiramo funkciju __load_conversations__ . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a772a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations():\n",
    "    # konstruiraj riječnik sa ključem (ID) filmske replike na vrijednost teksta filmske replike\n",
    "    id2line = {}\n",
    "    ## učitani tekst datoteke movie_lines.txt razdvoji u listu po linijama teksta \n",
    "    with open(path_to_movie_lines, errors=\"ignore\") as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    ## iz svake linije teksta izdvoji informacije\n",
    "    ### makni \\n znak za idući red iz teksta\n",
    "    ### razdvoji svaku liniju teksta sa obzirom na separator \" +++$+++ \"\n",
    "    for line in lines:\n",
    "        parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
    "        id2line[parts[0]] = parts[4]\n",
    "\n",
    "    #izdvoji parove filmskih replika na popis pitanja (eng. questions) i odgovora (eng. answers).\n",
    "    inputs, outputs = [], []\n",
    "    ## učitani tekst datoteke movie_conversations.txt razdvoji u listu po linijama teksta \n",
    "    with open(path_to_movie_conversations, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    ## iz svake linije teksta izdvoji informacije o razgovoru\n",
    "    ### makni \\n znak za idući red iz teksta\n",
    "    ### razdvoji svaku liniju teksta sa obzirom na separator \" +++$+++ \"\n",
    "    ### dohvati razgovor po listi identifikacijskih ključeva filmskih replika\n",
    "    #### preprocesiraj tekst filmske replike koristeći prethodno definiranu funkciju preprocess_sentence(sentence)\n",
    "    #### kada je dohvaćen maksimalan definiran broj parova filmskih replika na kojima će se model trenirati, stani\n",
    "    for line in lines:\n",
    "        parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(\", \")]\n",
    "        for i in range(len(conversation) - 1):\n",
    "            inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "            if len(inputs) >= MAX_SAMPLES:\n",
    "                return inputs, outputs\n",
    "    \n",
    "    # vrati skupove pitanja i odgovora\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a455c57",
   "metadata": {},
   "source": [
    "Sada možemo pozvati funkciju __load_conversations__, te tako dobiti učitane i preprocesirane upite i odgovore.\n",
    "\n",
    "Dobivene rezultate ćemo spremiti u liste nazvane __questions__ i __answers__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe17c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = load_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e0b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample question: there .\n",
      "Sample answer: where ?\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample question: {questions[15]}\")\n",
    "print(f\"Sample answer: {answers[15]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1ee82",
   "metadata": {},
   "source": [
    "### Tokeniziranje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc886509",
   "metadata": {},
   "source": [
    "Proces tokeniziranja unosa se sastoji od idućih koraka:\n",
    "\n",
    "1. Konstruiramo tokenizer (preslikajte tekst u ID i ID u tekst) koristeći TensorFlow Datasets SubwordTextEncoder.\n",
    "2. Tokeniziramo svaku rečenicu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700c777",
   "metadata": {},
   "source": [
    "#### Gradnja tokenizera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a386d1",
   "metadata": {},
   "source": [
    "Konstuiramo tokenizer koristeći tfds (TensorFlow Datasets SubwordTextEncoder) za liste pitanja i odgovora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5768cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d5bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sample question: [119, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokenized sample question: {tokenizer.encode(questions[15])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345f357",
   "metadata": {},
   "source": [
    "#### Tokeniziramo svaku rečenicu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cca3fc",
   "metadata": {},
   "source": [
    "Definiramo početni i završni token za označavanje početka i kraja rečenice.\n",
    "\n",
    "Definiramo varijablu _VOCAB_SIZE_ koja označava veličinu vokabulara tokenizera, sa pribrojenim +2 za \"razumijevanje\" počtnog i završnog tokena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5374fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd0b76",
   "metadata": {},
   "source": [
    "Tokeniziranje samo po sebi sadrži iduće korake: \n",
    "\n",
    "1. Dodajemo START_TOKEN i END_TOKEN da označimo početak i kraj svake rečenice.\n",
    "2. Filtriramo rečenicu koja ima više od MAX_LENGTH tokena.\n",
    "3. Dopunimo tokenizirane rečenice do duljine MAX_LENGTH\n",
    "\n",
    "Definiramo taj proces u funkciji __tokenize_and_filter__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0407c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        \n",
    "        # korak 1\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "        \n",
    "        # korak 2\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # korak 3\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding=\"post\"\n",
    "    )\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding=\"post\"\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4dec89",
   "metadata": {},
   "source": [
    "Sada završno, primjenom funkcije na liste __questions__ i __answers__ možemo dobiti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2900922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadbc189",
   "metadata": {},
   "source": [
    "Promotrimo sada veličin rječnika i broj primjera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "242991e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 8247\n",
      "Number of samples: 194612\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocab size: {VOCAB_SIZE}\")\n",
    "print(f\"Number of samples: {len(questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea303c7b",
   "metadata": {},
   "source": [
    "## Stvaranje tf.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fd573",
   "metadata": {},
   "source": [
    "Koristit ćemo [tf.data.Dataset API](https://www.tensorflow.org/api_docs/python/tf/data) za konstruiranje našeg ulaznog cjevovoda kako bismo iskoristili značajke kao što su predmemorija i prefetching kako bismo ubrzali proces treniranja modela.\n",
    "\n",
    "Transformator je auto-regresivni model: predviđa jedan po jedan dio i koristi svoj dosadašnji izlaz da odluči što dalje.\n",
    "\n",
    "Tijekom treninga ovaj primjer koristi metodu _teacher-forcing_. \n",
    "_Teacher-forcing_ je prosljeđivanje pravog izlaza na sljedeći vremenski korak bez obzira na to što model predviđa u trenutnom vremenskom koraku.\n",
    "\n",
    "Kako transformator predviđa svaku riječ, samopažnja mu omogućuje da pogleda prethodne riječi u rečenici unosa kako bi bolje predvidio sljedeću riječ.\n",
    "\n",
    "Kako bi se spriječilo da model dostigne samo očekivani rezultat, model koristi look-ahead masku.\n",
    "\n",
    "Target je podijeljen na _decoder_inputs_ koji se dodaju kao ulaz u dekoder, i _cropped_targets_ za izračun našeg gubitka i točnosti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb002a88",
   "metadata": {},
   "source": [
    "Unosi dekodera koriste prethodni target kao unos. \n",
    "Uklanja START_TOKEN sa targeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2e1f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"inputs\": questions, \"dec_inputs\": answers[:, :-1]},\n",
    "        {\"outputs\": answers[:, 1:]},\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b94337a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=({'inputs': TensorSpec(shape=(None, 40), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(None, 39), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(None, 39), dtype=tf.int32, name=None)})>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c7a24",
   "metadata": {},
   "source": [
    "## Mehanizam pažnje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee56193",
   "metadata": {},
   "source": [
    "### Pažnja skalarnog produkta\n",
    "\n",
    "Autori su verziju generalnog mehanizma pažnje korištene u originalnoj arhitekturi transformer modela nazvali pažnjom skalarnog produkta (eng. \\textit{scaled dot-product attention}). \n",
    "\n",
    "Funkcija pažnje koji koristi neuronska mreža transformer tako uzima tri ulaza: vrijednost upita $q$, vektor ključeva $\\overrightarrow{k}$ dimenzije $d_k$ i vektor vrijednosti $\\overrightarrow{v}$ dimenzije $d_v$. Vrijednost pondera $\\alpha_j$ vrijednosti $v_j$, gdje je $j \\in \\{ 1, \\dots , d_v \\} $, tako računamo kao primjenu $softmax()$ funkcije na skalarni umnožak upita $q$ sa vektorom $\\overrightarrow{k}$ svih ključeva podijeljen sa vrijednosti $\\sqrt{d_k}$. Skalarni umnožak upita i vektora ključeva se dijeli sa korijenom dimenzije $d_k$ jer za velike dimenzije vektora ključa skalarni umnožak postaje ogroman, što čini $softmax_k()$ funkciju manje preciznom.\n",
    "\n",
    "$$\\alpha_{j}=softmax_k(\\frac{q\\overrightarrow{k}^T}{\\sqrt{d_k}}), \\qquad \\text{gdje je} \\; j \\in \\{ 1, \\dots , d_v \\} $$\n",
    "\n",
    "Pa bi funkcija pažnje izgledala kao: \n",
    "$$Attention(q, \\overrightarrow{k}, \\overrightarrow{v})=\\sum^{d_v}_{i=1}\\alpha_{j}v_j, \\qquad \\text{gdje je} \\; j \\in \\{ 1, \\dots , d_v \\} $$\n",
    "\n",
    "U praksi, račun težina se izvodi tako da se funkcija pažnje izvodi na mnogo upita istovremeno. Izrazimo li tako niz upita kao matricu $Q$, te vektore ključeva i pripadnih vrijednosti kao matrice $K$ i $V$ redom, za račun funkcije pažnje možemo izraziti i kao: \n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "Kako bi se programski implementirao mehanizam pažnje skalarnog produkta, u programu se definira pomoćna funkcija `scaled_dot_product_attention(query, key, value, mask)`.\n",
    "\n",
    "Sa obzirom da smo pri izradi chatbot programa za normalizaciju unosa koristili tokene za popunjavanje, potrebno ih je nulirati prije računa mehanizma pažnje. Kako bi nulirali takve ćelije, korisno je primjetiti da su veliki negativni ulazi u funkciju $softmax()$ blizu nule u izlazu.\n",
    "\n",
    "Maska se tako množi sa iznosom $-1e9$ (što je blizu negativne beskonačnosti). To je učinjeno jer se maska zbraja s skaliranim matričnim množenjem $\\frac{QK^T}{\\sqrt{d_k}}$ i primjenjuje se neposredno prije ulaza u funkciju $softmax()$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1c018ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"Izračunaj težinske vrijednosti pažnje\"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # skaliraj matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # dodajte masku za nuliranje tokena za popunjavanje\n",
    "    if mask is not None:\n",
    "        logits += mask * -1e9\n",
    "\n",
    "    # softmax je normaliziran na zadnjoj osi (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c66de9",
   "metadata": {},
   "source": [
    "### Pažnja s više glava\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"pozornost s više glava\">\n",
    "\n",
    "\n",
    "Pažnja s više glava sastoji se od četiri dijela:\n",
    "\n",
    "* Linearnih slojeva podijeljenih u glave - Svaki blok pažnje s više glava dobiva tri ulaza: upit $Q$, ključ $K$ i vrijednost $V$. Oni su ulazi linearnih (eng. `Dense`) slojeva neuronske mreže, i dijele na više „glava”.Umjesto jedne glave pozornosti, \"upit\", \"ključ\" i \"vrijednost\" su podijeljeni u više glava jer to omogućuje modelu da zajedno prati informacije na različitim pozicijama iz različitih reprezentativnih prostora. \n",
    "\n",
    "\n",
    "* Pažnju skalarnog produkta - Nakon podjele ulaznih vrijednosti, svaka „glava” je smanjene dimenzije, pa je ukupni trošak izračuna mehanizma pažnje isti kao račun mehanizma pažnje sa samo jednom glavom pune dimenzionalnosti. Gore definirana funkcija `scaled_dot_product_attention(query, key, value, mask)` se primjenjuje na svaku glavu zasebno. Pri svakom koraku mehanizma pažnje se mora koristiti odgovarajuća maska. \n",
    "\n",
    "\n",
    "* Konkatenciju izlaznih vrijednosti glava - Izlazi mehanizma pažnje za svaku glavu se zatim konkateniraju (pomoću `tf.transpose` i `tf.reshape`).\n",
    "\n",
    "\n",
    "* Završni linearni sloj - Vrijednost konkatenacije izlaznih vrijednostnih glava zatim prolazi kroz završni, linearni (eng. `Dense`) sloj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac933034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, **kwargs):\n",
    "        assert d_model % num_heads == 0\n",
    "        super(MultiHeadAttentionLayer, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiHeadAttentionLayer, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"d_model\": self.d_model,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.keras.layers.Lambda(\n",
    "            lambda inputs: tf.reshape(\n",
    "                inputs, shape=(batch_size, -1, self.num_heads, self.depth)\n",
    "            )\n",
    "        )(inputs)\n",
    "        return tf.keras.layers.Lambda(\n",
    "            lambda inputs: tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "        )(inputs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = (\n",
    "            inputs[\"query\"],\n",
    "            inputs[\"key\"],\n",
    "            inputs[\"value\"],\n",
    "            inputs[\"mask\"],\n",
    "        )\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # split heads\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # scaled dot-product attention\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.keras.layers.Lambda(\n",
    "            lambda scaled_attention: tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        )(scaled_attention)\n",
    "\n",
    "        # concatenation of heads\n",
    "        concat_attention = tf.keras.layers.Lambda(\n",
    "            lambda scaled_attention: tf.reshape(\n",
    "                scaled_attention, (batch_size, -1, self.d_model)\n",
    "            )\n",
    "        )(scaled_attention)\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4487f",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebbb4c",
   "metadata": {},
   "source": [
    "### Maskiranje\n",
    "\n",
    "`create_padding_mask` i `create_look_ahead` pomoćne su funkcije za stvaranje maski za maskiranje podstavljenih tokena, te ćemo pomoćne funkcije koristiti kao slojeve `tf.keras.layers.Lambda`.\n",
    "\n",
    "Maskirajte sve tokene podloška (vrijednost `0`) u seriji kako biste osigurali da model ne tretira podmetanje kao ulaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56efbc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d452295",
   "metadata": {},
   "source": [
    "Maska unaprijed za maskiranje budućih tokena u nizu.\n",
    "Također maskiramo pad tokene.\n",
    "\n",
    "tj. Za predviđanje treće riječi koristit će se samo prva i druga riječ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "542738fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f6026",
   "metadata": {},
   "source": [
    "### Pozicijsko kodiranje\n",
    "\n",
    "Budući da ovaj model ne sadrži nikakvo ponavljanje ili konvoluciju, dodano je poziciono kodiranje kako bi se modelu dale neke informacije o relativnom položaju riječi u rečenici.\n",
    "\n",
    "Pozicijski vektor za kodiranje dodaje se vektoru za ugradnju. Ugrađivanja predstavljaju token u d-dimenzionalnom prostoru gdje će tokeni sa sličnim značenjem biti bliži jedni drugima. Ali ugradnje ne kodiraju relativni položaj riječi u rečenici. Dakle, nakon dodavanja pozicionog kodiranja, riječi će biti bliže jedna drugoj na temelju *sličnosti njihovog značenja i njihovog položaja u rečenici*, u d-dimenzionalnom prostoru.\n",
    "\n",
    "Formula za izračunavanje položajnog kodiranja je sljedeća:\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03ab8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.position = position\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEncoding, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"position\": self.position,\n",
    "                \"d_model\": self.d_model,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model,\n",
    "        )\n",
    "        # apply sin to even index in the array\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # apply cos to odd index in the array\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, : tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2698a855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512, name=\"sample_pos_encoding\")\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap=\"RdBu\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel(\"Position\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020be3ad",
   "metadata": {},
   "source": [
    "### Sloj enkodera \n",
    "\n",
    "Svaki sloj enkodera sastoji se od podslojeva:\n",
    "\n",
    "1. Pažnja za više glava (s podstavljenom maskom)\n",
    "2. 2 gusta sloja nakon čega slijedi ispadanje\n",
    "\n",
    "Svaki od ovih podslojeva ima zaostalu vezu oko sebe nakon koje slijedi normalizacija sloja. Preostale veze pomažu u izbjegavanju problema s nestajanjem gradijenta u dubokim mrežama.\n",
    "\n",
    "Izlaz svakog podsloja je `LayerNorm(x + Sublayer(x))`. Normalizacija se vrši na osi `d_model` (zadnja)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf7f3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention = MultiHeadAttentionLayer(d_model, num_heads, name=\"attention\")(\n",
    "        {\"query\": inputs, \"key\": inputs, \"value\": inputs, \"mask\": padding_mask}\n",
    "    )\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    add_attention = tf.keras.layers.add([inputs, attention])\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation=\"relu\")(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    add_attention = tf.keras.layers.add([attention, outputs])\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca66345",
   "metadata": {},
   "source": [
    "### Enkoder\n",
    "\n",
    "Enkoder se sastoji od:\n",
    "1. Ugradnja unosa\n",
    "2. Pozicijsko kodiranje\n",
    "3. `num_layers` slojevi kodera\n",
    "\n",
    "Ulaz se stavlja kroz ugrađivanje koje se zbraja s pozicijskim kodiranjem. \n",
    "Izlaz ovog zbrajanja je ulaz u slojeve kodera. \n",
    "Izlaz kodera je ulaz u dekoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a10df850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.keras.layers.Lambda(\n",
    "        lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    )(d_model)\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06aedb1",
   "metadata": {},
   "source": [
    "### Sloj dekodera\n",
    "\n",
    "Svaki sloj dekodera sastoji se od podslojeva:\n",
    "\n",
    "1. Maskirana pažnja s više glava (s maskom za pogled unaprijed i maskom za podstavu)\n",
    "2. Pažnja za više glava (s podstavnom maskom). `vrijednost` i `ključ` primaju *izlaz kodera* kao ulaze. `upit` prima *izlaz iz maskiranog podsloja pažnje s više glava.*\n",
    "3. 2 gusta sloja nakon čega slijedi ispadanje\n",
    "\n",
    "Svaki od ovih podslojeva ima zaostalu vezu oko sebe nakon koje slijedi normalizacija sloja. Izlaz svakog podsloja je `LayerNorm(x + Sublayer(x))`. Normalizacija se vrši na osi `d_model` (zadnja).\n",
    "\n",
    "Kako `query` prima izlaz iz prvog bloka pozornosti dekodera, a `key` prima izlaz kodera, težine pažnje predstavljaju važnost koja se pridaje ulazu dekodera na temelju izlaza kodera. Drugim riječima, dekoder predviđa sljedeću riječ gledajući izlaz kodera i samostalno prateći svoj izlaz. Pogledajte gornju demonstraciju u odjeljku pozornosti na skalirani točkasti proizvod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edaa708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention1 = MultiHeadAttentionLayer(d_model, num_heads, name=\"attention_1\")(\n",
    "        inputs={\n",
    "            \"query\": inputs,\n",
    "            \"key\": inputs,\n",
    "            \"value\": inputs,\n",
    "            \"mask\": look_ahead_mask,\n",
    "        }\n",
    "    )\n",
    "    add_attention = tf.keras.layers.add([attention1, inputs])\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    attention2 = MultiHeadAttentionLayer(d_model, num_heads, name=\"attention_2\")(\n",
    "        inputs={\n",
    "            \"query\": attention1,\n",
    "            \"key\": enc_outputs,\n",
    "            \"value\": enc_outputs,\n",
    "            \"mask\": padding_mask,\n",
    "        }\n",
    "    )\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    add_attention = tf.keras.layers.add([attention2, attention1])\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation=\"relu\")(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    add_attention = tf.keras.layers.add([outputs, attention2])\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18847da9",
   "metadata": {},
   "source": [
    "### Dekoder\n",
    "\n",
    "Dekoder se sastoji od:\n",
    "1. Ugradnja izlaza\n",
    "2. Pozicijsko kodiranje\n",
    "3. N slojeva dekodera\n",
    "\n",
    "Cilj se stavlja kroz ugrađivanje koje se zbraja s položajnim kodiranjem. \n",
    "Izlaz ovog zbrajanja je ulaz u slojeve dekodera. \n",
    "Izlaz dekodera je ulaz u konačni linearni sloj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "576d380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.keras.layers.Lambda(\n",
    "        lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    )(d_model)\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"decoder_layer_{}\".format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085dcbd",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "Transformer se sastoji od enkodera, dekodera i završnog linearnog sloja. Izlaz dekodera je ulaz u linearni sloj i njegov se izlaz vraća.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e1f9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(\n",
    "    vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"transformer\"\n",
    "):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name=\"enc_padding_mask\"\n",
    "    )(inputs)\n",
    "    # mask the future tokens for decoder inputs at the 1st attention block\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None), name=\"look_ahead_mask\"\n",
    "    )(dec_inputs)\n",
    "    # mask the encoder outputs for the 2nd attention block\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name=\"dec_padding_mask\"\n",
    "    )(inputs)\n",
    "\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de8508",
   "metadata": {},
   "source": [
    "## Treniranje modela\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa0ac5",
   "metadata": {},
   "source": [
    "### Funkcija gubitka (loss function)\n",
    "\n",
    "Budući da su ciljne sekvence dopunjene, važno je primijeniti masku dopune pri izračunavanju gubitka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e9bbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=\"none\"\n",
    "    )(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a0990",
   "metadata": {},
   "source": [
    "### Prilagođena stopa učenja\n",
    "\n",
    "Upotrijebljen je Adamov optimizator s prilagođenim planerom brzine učenja prema formuli u [radu](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2737ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = tf.constant(d_model, dtype=tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"d_model\": self.d_model, \"warmup_steps\": self.warmup_steps}\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.multiply(\n",
    "            tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0dea737a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0865e11",
   "metadata": {},
   "source": [
    "Inicijalizirajmo i kompajlirajmo model s našom unaprijed definiranom prilagođenom stopom učenja i uključenim Adam optimizatorom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab96700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear backend\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486dbc9",
   "metadata": {},
   "source": [
    "Za korištenje strategije pri treniranju modela je dovoljno inicijalizirati i kompilirati objekt model\n",
    "unutar opsega strategije strategy.scope()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18965f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    #inicijalizacija modela \n",
    "    model = transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        units=UNITS,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout=DROPOUT,\n",
    "    )\n",
    "\n",
    "    #kompilacija modela\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54214a",
   "metadata": {},
   "source": [
    "Sada pozovimo metodu model.summary() za ispis korisnog sažetka modela koji uključuje sljedeće:\n",
    "\n",
    "- Naziv i vrstu svih slojeva modela.\n",
    "\n",
    "- Izlazni obrazac za svaki sloj.\n",
    "\n",
    "- Broj težinskih parametara za svaki sloj.\n",
    "\n",
    "- Ako model ima opću topologiju, ulazi koje svaki sloj prima.\n",
    "\n",
    "- Ukupan broj parametara modela koji se mogu trenirati i koji se ne mogu trenirati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2ec83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 512)    10534400    ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 512)    14740992    ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8247)   4230711     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,506,103\n",
      "Trainable params: 29,506,103\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a163c6",
   "metadata": {},
   "source": [
    "Transformer se trenira sa jednostavnim pozivom `model.fit()` funkcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad174c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3041/3041 [==============================] - 315s 100ms/step - loss: 1.5717 - accuracy: 0.0742\n",
      "Epoch 2/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.3711 - accuracy: 0.0872\n",
      "Epoch 3/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.3252 - accuracy: 0.0904\n",
      "Epoch 4/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.2956 - accuracy: 0.0925\n",
      "Epoch 5/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.2757 - accuracy: 0.0940\n",
      "Epoch 6/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.2585 - accuracy: 0.0953\n",
      "Epoch 7/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.2438 - accuracy: 0.0964\n",
      "Epoch 8/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.2320 - accuracy: 0.0973\n",
      "Epoch 9/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.2208 - accuracy: 0.0981\n",
      "Epoch 10/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.2107 - accuracy: 0.0989\n",
      "Epoch 11/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.2014 - accuracy: 0.0997\n",
      "Epoch 12/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.1935 - accuracy: 0.1002\n",
      "Epoch 13/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.1854 - accuracy: 0.1010\n",
      "Epoch 14/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1781 - accuracy: 0.1016\n",
      "Epoch 15/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1705 - accuracy: 0.1021\n",
      "Epoch 16/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.1631 - accuracy: 0.1029\n",
      "Epoch 17/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1560 - accuracy: 0.1034\n",
      "Epoch 18/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1494 - accuracy: 0.1040\n",
      "Epoch 19/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1437 - accuracy: 0.1044\n",
      "Epoch 20/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1375 - accuracy: 0.1051\n",
      "Epoch 21/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.1320 - accuracy: 0.1055\n",
      "Epoch 22/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1268 - accuracy: 0.1060\n",
      "Epoch 23/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.1217 - accuracy: 0.1065\n",
      "Epoch 24/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1165 - accuracy: 0.1069\n",
      "Epoch 25/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1118 - accuracy: 0.1074\n",
      "Epoch 26/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1077 - accuracy: 0.1078\n",
      "Epoch 27/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.1036 - accuracy: 0.1081\n",
      "Epoch 28/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0992 - accuracy: 0.1085\n",
      "Epoch 29/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0953 - accuracy: 0.1089\n",
      "Epoch 30/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0913 - accuracy: 0.1092\n",
      "Epoch 31/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0875 - accuracy: 0.1096\n",
      "Epoch 32/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.0843 - accuracy: 0.1099\n",
      "Epoch 33/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0807 - accuracy: 0.1103\n",
      "Epoch 34/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0770 - accuracy: 0.1106\n",
      "Epoch 35/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0737 - accuracy: 0.1109\n",
      "Epoch 36/40\n",
      "3041/3041 [==============================] - 304s 100ms/step - loss: 1.0705 - accuracy: 0.1112\n",
      "Epoch 37/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0675 - accuracy: 0.1115\n",
      "Epoch 38/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0644 - accuracy: 0.1119\n",
      "Epoch 39/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0616 - accuracy: 0.1121\n",
      "Epoch 40/40\n",
      "3041/3041 [==============================] - 303s 100ms/step - loss: 1.0585 - accuracy: 0.1125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe970737940>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f4ab64",
   "metadata": {},
   "source": [
    "Sada natrenirani model spremimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, filepath=\"model.h5\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8b996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
